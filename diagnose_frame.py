#!/usr/bin/env python3
"""
Frame Diagnosis Tool - Analyze why model isn't detecting objects
"""

import cv2
import json
import os
from datetime import datetime
from pathlib import Path

def analyze_frame():
    """Capture and analyze frame"""
    print("\n" + "="*80)
    print("ğŸ” FRAME DIAGNOSIS TOOL")
    print("="*80)
    
    # Capture frame
    print("\nğŸ“· Capturing frame from webcam...")
    cap = cv2.VideoCapture(1)
    
    if not cap.isOpened():
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ Cannot open webcam")
            return
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    for _ in range(5):
        cap.read()
    
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("âŒ Failed to capture")
        return
    
    print(f"âœ… Frame captured: {frame.shape}")
    
    # Save frame
    TEST_DIR = Path("./test_output")
    TEST_DIR.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    frame_path = TEST_DIR / f"diagnosis_frame_{timestamp}.jpg"
    cv2.imwrite(str(frame_path), frame)
    print(f"ğŸ’¾ Frame saved: {frame_path}")
    
    # Analyze frame properties
    print("\n" + "="*80)
    print("ğŸ“Š FRAME ANALYSIS")
    print("="*80)
    
    # Size
    height, width = frame.shape[:2]
    print(f"\nğŸ“ DIMENSIONS: {width}x{height}")
    
    # Color space
    if len(frame.shape) == 3:
        channels = frame.shape[2]
        print(f"ğŸ¨ COLOR CHANNELS: {channels} (BGR)")
    
    # Brightness
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    brightness = gray.mean()
    print(f"ğŸ’¡ BRIGHTNESS: {brightness:.1f}/255")
    
    if brightness < 50:
        print("   âš ï¸  VERY DARK - Detection will struggle")
    elif brightness < 100:
        print("   âš ï¸  DARK - Detection may be poor")
    elif brightness > 200:
        print("   âš ï¸  VERY BRIGHT - May have glare/washout")
    else:
        print("   âœ… Good lighting")
    
    # Contrast
    contrast = gray.std()
    print(f"ğŸ“Š CONTRAST: {contrast:.1f}")
    
    if contrast < 20:
        print("   âš ï¸  LOW CONTRAST - Objects blend into background")
    elif contrast > 100:
        print("   âœ… Good contrast")
    else:
        print("   âœ… Acceptable contrast")
    
    # Motion blur detection
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    sharpness = laplacian.var()
    print(f"ğŸ” SHARPNESS: {sharpness:.1f}")
    
    if sharpness < 100:
        print("   âš ï¸  BLURRY - Motion blur or focus issue")
    else:
        print("   âœ… Sharp image")
    
    # Check for people/objects presence
    print("\n" + "="*80)
    print("ğŸ‘¥ OBJECT PRESENCE CHECK")
    print("="*80)
    
    print("\nâ“ Is there a person visible in the webcam?")
    print("   To debug, check:")
    print("   1. Is the person actually visible on screen right now?")
    print("   2. Is the person large enough in frame? (occupies ~10% or more)")
    print("   3. Is lighting good enough to see the person clearly?")
    print("   4. Is the person facing towards the camera?")
    
    # Edge detection to find objects
    edges = cv2.Canny(gray, 50, 150)
    edge_density = (edges > 0).sum() / edges.size * 100
    print(f"\nğŸ”² EDGE DENSITY: {edge_density:.1f}%")
    
    if edge_density < 5:
        print("   âš ï¸  Very few edges - might be blank/uniform scene")
    elif edge_density > 30:
        print("   âœ… Many edges - objects/people likely present")
    
    # Save analysis
    analysis = {
        "timestamp": timestamp,
        "dimensions": {"width": width, "height": height},
        "brightness": float(brightness),
        "contrast": float(contrast),
        "sharpness": float(sharpness),
        "edge_density": float(edge_density),
        "diagnostics": {
            "lighting": "GOOD" if 100 <= brightness <= 200 else "CHECK",
            "contrast": "GOOD" if contrast > 20 else "CHECK",
            "sharpness": "GOOD" if sharpness > 100 else "CHECK",
            "has_objects": "LIKELY" if edge_density > 10 else "CHECK"
        }
    }
    
    json_path = TEST_DIR / f"diagnosis_{timestamp}.json"
    with open(json_path, "w") as f:
        json.dump(analysis, f, indent=2)
    
    print(f"\nğŸ’¾ Analysis saved: {json_path}")
    
    # Save edge detection
    edge_path = TEST_DIR / f"diagnosis_edges_{timestamp}.jpg"
    cv2.imwrite(str(edge_path), edges)
    print(f"ğŸ”² Edge map saved: {edge_path}")
    
    # Recommendations
    print("\n" + "="*80)
    print("ğŸ’¡ RECOMMENDATIONS")
    print("="*80)
    
    recommendations = []
    
    if brightness < 100:
        recommendations.append("âŒ Frame is too dark - improve lighting")
    
    if contrast < 20:
        recommendations.append("âŒ Low contrast - check background/clothing")
    
    if sharpness < 100:
        recommendations.append("âŒ Image is blurry - check focus or reduce motion")
    
    if edge_density < 10:
        recommendations.append("âŒ Very few objects detected - ensure person is in frame")
    
    if not recommendations:
        print("âœ… Frame quality looks good!")
        print("   If model still returns empty predictions:")
        print("   - Try moving person closer to camera")
        print("   - Ensure person is fully visible")
        print("   - Try different angles/backgrounds")
    else:
        print("\n".join(recommendations))
    
    print("\n" + "="*80)
    print("\nğŸ“ NEXT STEPS:")
    print("1. Check the saved frame_*.jpg - is person visible?")
    print("2. Check the edges_*.jpg - do you see person outline?")
    print("3. If person is visible in frame but edges show nothing,")
    print("   there may be a preprocessing issue")
    print("4. Run quick_test.py again after fixing any issues")

if __name__ == "__main__":
    analyze_frame()
